{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Masking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools as it\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    img_lists = os.listdir(folder)\n",
    "    img_lists = sorted(img_lists, key=lambda p: int(Path(p).stem))\n",
    "    for filename in img_lists:\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '../data/datasets/vegetable_dog/images'\n",
    "images = load_images_from_folder(images_path)\n",
    "sample_size = 10\n",
    "sequential = True\n",
    "plot_dpi = 300\n",
    "\n",
    "images_count = len(images)\n",
    "if sequential:\n",
    "    start = random.randint(0, images_count - sample_size)\n",
    "    taken_images_index = [*range(start, start + sample_size)]\n",
    "else:\n",
    "    taken_images_index = random.sample(range(images_count), sample_size if images_count > sample_size else images_count)\n",
    "print('Taken {} from {} images'.format(taken_images_index, images_count))\n",
    "\n",
    "sample_images = [images[i] for i in taken_images_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_samples(images):\n",
    "    fig, ax = plt.subplots(1, len(images), figsize=(14.5, 6), constrained_layout=True, sharey=True)\n",
    "    fig.set_dpi(plot_dpi)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        ax[i].set_title('Color Image {}'.format(i))\n",
    "        ax[i].imshow(images[i])\n",
    "\n",
    "display_samples(sample_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Objects by Masks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "thirdparty_dir = os.path.join(os.getcwd(), '../thirdparty')\n",
    "sys.path.append(thirdparty_dir)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Running inference on device \\'{}\\''.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DIS.IS_Net.data_loader_cache import normalize, im_reader, im_preprocess \n",
    "from DIS.IS_Net.models.isnet import ISNetGTEncoder, ISNetDIS\n",
    "\n",
    "hypar = {\n",
    "    'model_path': '../data/models/is-net',  # load trained weights from this path\n",
    "    'restore_model': 'isnet.pth',           # name of the to-be-loaded weights\n",
    "    'interm_sup': False,                    # indicate if activate intermediate feature supervision\n",
    "    'model_digit': 'full',                  # indicates 'half' or 'full' accuracy of float number\n",
    "    'seed': 0,\n",
    "    'cache_size': [1024, 1024],             # cached input spatial resolution, can be configured into different size\n",
    "    'input_size': [1024, 1024],             # mdoel input spatial size, usually use the same value hypar['cache_size'], which means we don't further resize the images\n",
    "    'crop_size': [1024, 1024],              # random crop size from the input, it is usually set as smaller than hypar['cache_size'], e.g., [920,920] for data augmentation\n",
    "    'model': ISNetDIS()\n",
    "}                                           # paramters for inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hypar, device):\n",
    "    net = hypar['model'] # GOSNETINC(3, 1)\n",
    "    # convert to half precision\n",
    "    if(hypar['model_digit'] == 'half'):\n",
    "        net.half()\n",
    "        for layer in net.modules():\n",
    "            if isinstance(layer, torch.nn.BatchNorm2d):\n",
    "                layer.float()\n",
    "    net.to(device)\n",
    "    if(hypar['restore_model'] != ''):\n",
    "        net.load_state_dict(torch.load(hypar['model_path'] + '/' + hypar['restore_model'], map_location=device))\n",
    "        net.to(device)\n",
    "    net.eval() \n",
    "    return net\n",
    "\n",
    "dis_net_full = build_model(hypar, device)\n",
    "dis_net_full.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the Image using torch.transforms\n",
    "class GOSNormalize(object):\n",
    "    def __init__(self, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, image):\n",
    "        image = normalize(image, self.mean, self.std)\n",
    "        return image\n",
    "\n",
    "transform = transforms.Compose([GOSNormalize([0.5, 0.5, 0.5], [1.0, 1.0, 1.0])])\n",
    "\n",
    "def normalize_2_tensor_with_size(im, hypar):\n",
    "    im, im_shp = im_preprocess(im, hypar['cache_size'])\n",
    "    im = torch.divide(im, 255.0)\n",
    "    shape = torch.from_numpy(np.array(im_shp))\n",
    "    return transform(im).unsqueeze(0), shape.unsqueeze(0) \n",
    "\n",
    "normalized_sample_images = [normalize_2_tensor_with_size(im, hypar) for im in sample_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_predict_masks(dis_net, images_tensor_with_size):\n",
    "    predicted_masks = []\n",
    "    time_ms = []\n",
    "\n",
    "    for (inputs_val, shapes_val) in images_tensor_with_size:\n",
    "        inputs_val = inputs_val.type(torch.FloatTensor if hypar['model_digit'] == 'full' else torch.HalfTensor)\n",
    "        inputs_val_v = torch.autograd.Variable(inputs_val, requires_grad=False).to(device) # wrap inputs in Variable\n",
    "\n",
    "        b = datetime.datetime.now()\n",
    "        ds_val = dis_net(inputs_val_v)[0] # list of 6 results\n",
    "        e = datetime.datetime.now()\n",
    "        time_ms.append((e - b).microseconds / 1000)\n",
    "\n",
    "        pred_val = ds_val[0][0, :, :, :] # B x 1 x H x W, we want the first one which is the most accurate prediction\n",
    "        # recover the prediction spatial size to the orignal image size\n",
    "        pred_val = torch.squeeze(torch.nn.functional.upsample(\n",
    "            torch.unsqueeze(pred_val, 0), (shapes_val[0][0], shapes_val[0][1]),\n",
    "            mode='bilinear')\n",
    "        )\n",
    "        ma = torch.max(pred_val)\n",
    "        mi = torch.min(pred_val)\n",
    "        pred_val = (pred_val - mi) / (ma - mi) # max = 1\n",
    "        mask = (pred_val.detach().cpu().numpy() * 255).astype(np.uint8) # it is the mask we need\n",
    "        predicted_masks.append(mask)\n",
    "    \n",
    "    return predicted_masks, time_ms\n",
    "\n",
    "dis_full_predicted_masks, dis_full_time_ms = dis_predict_masks(dis_net_full, normalized_sample_images)\n",
    "print(dis_full_time_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def display_mask_results(original_images, masks):\n",
    "    fig, ax = plt.subplots(\n",
    "        len(original_images), 2, figsize=(14.5, 4 * len(original_images)),\n",
    "        gridspec_kw={'width_ratios': [2, 1]},\n",
    "        constrained_layout=True, sharey=True\n",
    "    )\n",
    "    fig.set_dpi(plot_dpi)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(0, len(original_images)):\n",
    "        mask_3 = cv2.cvtColor(masks[i], cv2.COLOR_GRAY2RGB)\n",
    "        (h0, w0), (h1, w1) = original_images[i].shape[:2], mask_3.shape[:2]\n",
    "        stitch_image = np.empty((max(h0, h1), w0 + w1, 3), dtype=np.uint8)\n",
    "        stitch_image[:h0, :w0, :3] = original_images[i]\n",
    "        stitch_image[:h1, w0:, :3] = mask_3\n",
    "        pil_mask = Image.fromarray(mask_3).convert('L')\n",
    "        pil_img = Image.fromarray(original_images[i])\n",
    "        pil_img_rgba = pil_img.copy()\n",
    "        pil_img_rgba.putalpha(pil_mask)\n",
    "        \n",
    "        ax[i, 0].set_title('Original Image {} / Mask'.format(i))\n",
    "        ax[i, 0].imshow(stitch_image)\n",
    "        ax[i, 1].set_title('Masked Image {}'.format(i))\n",
    "        ax[i, 1].imshow(pil_img_rgba)\n",
    "        \n",
    "display_mask_results(sample_images, dis_full_predicted_masks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference (Half Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypar['model_digit'] = 'half'\n",
    "dis_net_half = build_model(hypar, device)\n",
    "dis_net_half.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_half_predicted_masks, dis_half_time_ms = dis_predict_masks(dis_net_half, normalized_sample_images)\n",
    "print(dis_half_time_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_mask_results(sample_images, dis_half_predicted_masks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def display_time_consumption(durations_with_name):\n",
    "    total_width, n = 0.8, len(durations_with_name)\n",
    "    width = total_width / n\n",
    "    x_max = 0\n",
    "    cmap = cm.get_cmap()\n",
    "\n",
    "    plt.figure(figsize=(14.5, 5), dpi=plot_dpi)\n",
    "    plt.xlabel('DIS Predict Index')\n",
    "    plt.ylabel('Time (ms)')\n",
    "    plt.title('Time Consumption for Each Prediction')\n",
    "\n",
    "    for ((y, t), i) in zip(durations_with_name, range(0, n)):\n",
    "        x = np.arange(0, len(y))\n",
    "        x_max = max(len(y), x_max)\n",
    "        avg = np.average(y)\n",
    "        color = cmap(y * 255)\n",
    "        \n",
    "        bar = plt.bar(x + (i * width - (total_width - width) / 2), y, width=width, label='{}, average {:.3f}ms'.format(t, avg))\n",
    "        axhline = plt.axhline(avg, color=bar.patches[0].get_facecolor(), linestyle='--')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.xticks(range(0, x_max, 1))\n",
    "    plt.yscale('function', functions=(lambda v: v ** 0.5, lambda v: v ** 2))\n",
    "\n",
    "dis_half_time_ms = [741.184, 857.849, 18.552, 938.649, 347.034, 197.042, 740.818, 152.959, 817.542, 331.542] # test only\n",
    "\n",
    "durations_with_name = [\n",
    "    (dis_full_time_ms, 'DIS (FP32, CPU, M1)'),\n",
    "    (dis_half_time_ms, 'DIS (FP16, CPU, M1, test only)')\n",
    "]\n",
    "\n",
    "display_time_consumption(durations_with_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SfM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5354608d47e8d3d40283fd6505b86116d9905b298f75dd83c53ff0767e8880c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
